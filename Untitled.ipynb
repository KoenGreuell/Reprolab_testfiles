{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021b3a68-b037-4c73-aeef-c38e705dc265",
   "metadata": {},
   "source": [
    "# ReproLab Demo\n",
    "\n",
    "Welcome to ReproLab! This extension helps you make your research more reproducible.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Create Experiments**: Automatically save immutable snapshots of your code under `git` tags to preserve the **exact code and outputs**\n",
    "- **Manage Dependencies**: Automatically gather and pin **exact package versions**, so that others can set up your environment with one command\n",
    "- **Cache Data**: Call external API/load manually dataset only once, caching function will handle the rest\n",
    "- **Archive Data**: Caching function can also preserve the compressed data in *AWS S3*, so you always know what data was used and reduce the API calls\n",
    "- **Publishing guide**: The reproducibility checklist & automated generation of reproducability package make publishing to platforms such as Zenodo very easy\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "1. Use the sidebar to view ReproLab features\n",
    "2. Create virtual environment and pin your dependencies, go to reprolab section `Create reproducible environment` \n",
    "3. Create an experiment to save your current state, go to reprolab section `Create experiment`\n",
    "4. Archive your data for long-term storage, go to reprolab section `Demo` and play around with it.\n",
    "5. Publish your work when ready, remember to use reproducability checklist from the section `Reproducibility Checklist`\n",
    "\n",
    "## Example Usage of persistio decorator\n",
    "\n",
    "To cache and archive the datasets you use, both from local files and APIs we developed a simple decorator that put over your function that gets the datasets caches the file both locally and in the cloud so that the dataset you use is archived and the number of calls to external APIs is minimal and you don't need to keep the file around after you run it once.\n",
    "\n",
    "Here is an example using one of NASA open APIs. If you want to test it out yourself, you can copy the code, but you need to provide bucket name and access and secret key in the left-hand panel using the `AWS S3 Configuration` section.\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# The two lines below is all that you need to add\n",
    "from reprolab.experiment import persistio\n",
    "@persistio()\n",
    "def get_exoplanets_data_from_nasa():\n",
    "    url = \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT TOP 10\n",
    "        pl_name AS planet_name,\n",
    "        hostname AS host_star,\n",
    "        pl_orbper AS orbital_period_days,\n",
    "        pl_rade AS planet_radius_earth,\n",
    "        disc_year AS discovery_year\n",
    "    FROM\n",
    "        ps\n",
    "    WHERE\n",
    "        default_flag = 1\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"csv\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        df = pd.read_csv(StringIO(response.text))\n",
    "        \n",
    "        print(df)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "    return df\n",
    "\n",
    "exoplanets_data = get_exoplanets_data_from_nasa()\n",
    "```\n",
    "\n",
    "If you run this cell twice you will notice from the logs that the second time file was read from the compressed file in the cache. If you were to lose access to local cache (e.g. by pulling the repository using different device) `persistio` would fetch the data from the cloud archive.\n",
    "\n",
    "\n",
    "For more information, visit our [documentation](https://github.com/your-repo/reprolab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaece49c-a19e-4d9a-8ba9-0bcf417607de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78443bc2-9bdc-4af1-8e93-89f0939b7da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 14:34:23 - INFO - Starting experiment process\n",
      "2025-09-19 14:34:23 - INFO - Step 1: Saving all notebooks\n",
      "2025-09-19 14:34:23 - INFO - Attempting to save all Jupyter notebooks...\n",
      "2025-09-19 14:34:23 - INFO - ipylab save command executed successfully\n",
      "2025-09-19 14:34:24 - INFO - nbformat processing completed for 1 notebooks\n"
     ]
    }
   ],
   "source": [
    "from reprolab.experiment import start_experiment\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd17295e-2d7c-492e-bfbe-b912b82a086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprolab.experiment import end_experiment\n",
    "end_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reprolab]",
   "language": "python",
   "name": "conda-env-reprolab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
